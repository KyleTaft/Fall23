{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "# Linear Regression\n",
    "\n",
    "### Recap\n",
    "A linear model makes a prediction by computing a weighted sum of the input features and a constant (bias).    \n",
    "Basic linear regression model: $\\hat{y}$ = $\\theta$<sub>0</sub> + $\\theta$<sub>1</sub>x<sub>1</sub> + $\\theta$<sub>2</sub>x<sub>2</sub> + ... + $\\theta$<sub>n</sub>x<sub>n</sub>    \n",
    "* $\\hat{y}$ is the predicted value   \n",
    "* n is the number of features\n",
    "* x<sub>i</sub> is the i<sup>th</sup> feature value\n",
    "* $\\theta$<sub>j</sub> is the j<sup>th</sup> model parameter ($\\theta$<sub>0</sub> is the bias term; $\\theta$<sub>1</sub> .. $\\theta$<sub>n</sub> are the feature weights)   \n",
    "\n",
    "Using linear algebra we can work with this equation in its closed form solution (also called normal equation). Recall the closed form solution for linear regression from class: w* = (X<sup>T</sup>X)<sup>-1</sup> X<sup>T</sup>y\n",
    "\n",
    "We can think of the weights (w*) as the general parameter, $\\theta$: $\\hat{\\theta}$ = (X<sup>T</sup>X)<sup>-1</sup> X<sup>T</sup>y\n",
    "\n",
    "$\\hat{\\theta}$ is the values of $\\theta$ that minimizes the cost function    \n",
    "y is the target vector (i.e., labels or actual y values) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "### Part 1: Closed Form Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "stoic_sol",
    "state": "read_only"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "high_ran",
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "# For plots\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "sharp_hel",
    "state": "read_only"
   },
   "outputs": [],
   "source": [
    "# Create linear-like data to test first equation\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "\n",
    "# Function for generating data: y = 4 + 3x_1 + Gaussian noise\n",
    "# So theta0 = 4 & theta1 = 3\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "green_odin",
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "# Visualize dataset \n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.axis([0, 2, 0, 15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "sly_hel",
    "state": "read_only"
   },
   "outputs": [],
   "source": [
    "# Add x0 = 1 to each instance\n",
    "X2 = np.c_[np.ones((100, 1)), X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "big_oor",
    "starter_code": "# Use linalg inv & dot to calculate the closed form solution with X2 & y\ntheta_hat = ",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Use linalg inv & dot to calculate the closed form solution with X2 & y\n",
    "theta_hat = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "# Print theta_hat\n",
    "theta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "gray_vali",
    "starter_code": "# TODO: Answer in the comments\n# theta_hat should print values around [4.3, 2.8]-ish\n# But theta0 = 4 & theta1 = 3\n# Why couldn't we recover the exact parameters of our original function?\n# Your answer: ",
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "# TODO: Answer in the comments\n",
    "# theta_hat should print values around [4.3, 2.8]-ish\n",
    "# But theta0 = 4 & theta1 = 3\n",
    "# Why couldn't we recover the exact parameters of our original function?\n",
    "# Your answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "fit_loki",
    "starter_code": "# Task of the next 3 cells: Make a prediction using theta_hat\n# Create a new dataset (what dimensions should it be?)\nX_new = \n",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Task of the next 3 cells: Make a prediction using theta_hat\n",
    "# Create a new dataset (what dimensions should it be?)\n",
    "X_new = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "calm_magni",
    "starter_code": "# Add x0 = 1 to each instance\nX_new2 = ",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Add x0 = 1 to each instance\n",
    "X_new2 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "red_sol",
    "starter_code": "# Use your model to make a prediction on your new dataset\ny_predict = ",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Use your model to make a prediction on your new dataset\n",
    "y_predict = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "# Print y_predict\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "big_thor",
    "starter_code": "# Plot your new model's predictions\n# You should see a red line falling mostly in the middle of the blue data points\nplt.plot( , , \"r-\")\n\n# Plots the original data\nplt.plot(X, y, \"b.\")\nplt.axis([0, 2, 0, 15])\nplt.show( )",
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "# Plot your new model's predictions\n",
    "# You should see a red line falling mostly in the middle of the blue data points\n",
    "plt.plot(X_new, y_predict, \"r-\")\n",
    "\n",
    "# Plots the original data\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.axis([0, 2, 0, 15])\n",
    "plt.show( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "### Part 2: Using Scikit-Learn\n",
    "Scikit-Learn's LinearRegression class is based on scipy.linalg.lstsq() (Least Squares). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "red_ran",
    "starter_code": "# Import the LinearRegression class\nfrom sklearn.",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Import the LinearRegression class\n",
    "from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "stoic_loki",
    "starter_code": "# Create a LinearRegression instance\nlin_reg = ",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Create a LinearRegression instance\n",
    "lin_reg = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "sly_boi",
    "starter_code": "# Fit your model\n# NOTE: there is a bug in Windows for this method\n# If you get this error: ValueError: illegal value in 4th argument of internal None\n# Go to the previous cell and create your class instance with the argument: normalize = True\n",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Fit your model\n",
    "# NOTE: there is a bug in Windows for this method\n",
    "# If you get this error: ValueError: illegal value in 4th argument of internal None\n",
    "# Go to the previous cell and create your class instance with the argument: normalize = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "red_odin",
    "scrolled": true,
    "starter_code": "# Print the intercept of your model\n",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Print the intercept of your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "big_ran",
    "starter_code": "# Print the estimated coefficients of your model\n",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Print the estimated coefficients of your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "red_saga",
    "starter_code": "# Use your model to make a prediction on X_new\n# Don't need to answer: are your results similar to y_predict?\n",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Use your model to make a prediction on X_new\n",
    "# Are your results similar to y_predict?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "### Part3: Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "aged_sol",
    "starter_code": "# Import the SGDRegressor class\nfrom sklearn.",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Import the SGDRegressor class\n",
    "from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "eager_mimir",
    "starter_code": "# Create an SGDRegressor with\n# Maximum number of iterations = 1000\n# Training stopping criterion of 1e-3 \n# Ridge regularization term\n# Initial learning rate of 0.001\nsgd_reg = ",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Create an SGDRegressor with\n",
    "# Maximum number of iterations = 1000\n",
    "# Training stopping criterion of 1e-3 \n",
    "# Ridge regularization term\n",
    "# Initial learning rate of 0.001\n",
    "sgd_reg = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "gray_odin",
    "starter_code": "# Fit the model \n",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Fit the model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "able_vali",
    "starter_code": "# Print the intercept\n",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Print the intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "spicy_nott",
    "starter_code": "# Print the estimated coefficients\n",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Print the estimated coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "The intercept and coefficient should be close to the values of $\\hat{\\theta}$ found by the closed form solution in Part 1. If they're not, you can change the regularization and learning rate until you find values that work better. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "mimir": {
   "data": {},
   "last_submission_id": "",
   "project_id": "dfd2074c-02bf-4aac-8aa5-af16de004f02"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
