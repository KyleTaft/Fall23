{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPZcfoYofkY5",
    "state": "normal"
   },
   "source": [
    "# **Logistic Regression**\n",
    "Logistic Regression can be used to estimate the probability that an instance/sample/example belongs to a particular class. For example, what is the probability that an email is spam? If the estimated probability is greater than 50% (or a given threshold), then the LR model will predict that an instance belongs to that class (the positive class, usually labeled \"1\" or sometimes \"True\"). Otherwise the LR model predicts it does not belong to that class, therefore it belongs to the negative class, usually labeled \"0\". \n",
    "\n",
    "Similar to Linear Regression, Logistic Regression computes a weighted sum of the input features (plus a bias term), but instead of outputting the result directly (like linear regression), it outputs the logistic of that result: $\\hat{p} = h_{\\theta}(\\textbf{x}) = \\sigma(\\textbf{x}^T\\theta)$.\n",
    "\n",
    "The logistic ($\\sigma(*)$) is a sigmoid function (S-shaped like we saw in class) that will output a number between 0 and 1. Once we estimate the probability $\\hat{p}$ that an instance belongs to the positive class, then we can make the $\\hat{y}$ prediction easily: $\\hat{y} = 0  \\text{ if } \\hat{p} < 0.5 \\text{ or } \\hat{y} = 1 \\text{ if } \\hat{p} \\geq 0.5$. \n",
    "\n",
    "**Training and Cost Function**\n",
    "\n",
    "The training objective for LR is to set the parameter vector $\\theta$ so that the LR model will estimate high probabilities for positive instances (y = 1) and low probabilities for negative instances (y = 0). This can be expressed with this cost function: $c(\\theta) = -log(\\hat{p}) \\text{ if } y = 1, -log(1 - \\hat{p}) \\text{ if } y = 0$. \n",
    "\n",
    "The loss function for the whole training dataset is the average cost over all training instances. This is called the $\\textit{log loss}$: $J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m}[y^{(i)}log(\\hat{p^{(i)}}) + (1-y^{(i)})log(1-\\hat{p^{(i)}})]$ and we can solve it using Gradient Descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "**Basic Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "01",
    "state": "read_only"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "f_pd-AV2cfzb",
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "# For plots\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "02",
    "state": "read_only"
   },
   "outputs": [],
   "source": [
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "ZglxCyN1fXi2",
    "outputId": "8189e03f-4b36-462c-ce73-62c98abb2fa7",
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "# Let's first visualize the logistic function\n",
    "\n",
    "t = np.linspace(-10, 10, 100)\n",
    "sig = 1 / (1 + np.exp(-t))\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.plot([-10, 10], [0, 0], \"k-\")\n",
    "plt.plot([-10, 10], [0.5, 0.5], \"k:\")\n",
    "plt.plot([-10, 10], [1, 1], \"k:\")\n",
    "plt.plot([0, 0], [-1.1, 1.1], \"k-\")\n",
    "plt.plot(t, sig, \"b-\", linewidth=2, label=r\"$\\sigma(t) = \\frac{1}{1 + e^{-t}}$\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.legend(loc=\"upper left\", fontsize=20)\n",
    "plt.axis([-10, 10, -0.1, 1.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "03",
    "outputId": "c2bdb518-dc3f-47a9-8afd-503752c2eb37",
    "state": "read_only"
   },
   "outputs": [],
   "source": [
    "# Load the Iris Dataset from Scikit Learn to train and test on\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "list(iris.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "04",
    "outputId": "df88d173-ff58-4d22-b50f-362520712e0a",
    "state": "read_only"
   },
   "outputs": [],
   "source": [
    "# Look at the dataset details\n",
    "\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tWw0rImh5OZ",
    "state": "normal"
   },
   "source": [
    "# Working with only a Single Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "05",
    "starter_code": "# The data is in iris[\"data\"] and target in iris[\"target\"]\n# For this section, we will work with a single feature 'petal width'\n# which is the last (fourth) feature in iris[\"data\"]\n# We will assign class y=1 if the target's value is 2 and 0 otherwise\n\n# petal width\nX = \n# 1 if Iris virginica, else 0\ny =  ",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# The data is in iris[\"data\"] and target in iris[\"target\"]\n",
    "# For this section, we will work with a single feature 'petal width'\n",
    "# which is the last (fourth) feature in iris[\"data\"]\n",
    "# We will assign class y=1 if the target's value is 2 and 0 otherwise\n",
    "\n",
    "# petal width\n",
    "X = \n",
    "# 1 if Iris virginica, else 0\n",
    "y =  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "06",
    "outputId": "1791f8f2-525a-4fe4-9e9e-adaddb0c93a0",
    "starter_code": "# Import the LogisticRegression class from scikit learn\n\nfrom sklearn.",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Import the LogisticRegression class from scikit learn\n",
    "\n",
    "from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "07",
    "starter_code": "# Initialize the LogisticRegression class, use lbfgs solver and random state of 42\n\nlog_reg = ",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Initialize the LogisticRegression class, use lbfgs solver and random state of 42\n",
    "\n",
    "log_reg = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "08",
    "starter_code": "# Fit the data\n\nlog_reg.",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Fit the data\n",
    "\n",
    "log_reg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "09",
    "starter_code": "# Print the estimated coefficients of the learned function\n\n",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Print the estimated coefficients of the learned function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "10",
    "starter_code": "# Create new data and predict their classes\n# Create 1000 new datapoints between 0 and 1 and predict their probability using the trained model\n\nX_new = \ny_proba = ",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Create new data and predict their classes\n",
    "# Create 1000 new datapoints between 0 and 1 and predict their probability using the trained model\n",
    "\n",
    "X_new = \n",
    "y_proba = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "A5JnCyJtg37p",
    "outputId": "a85849db-ad9d-4ba4-9f88-d02535b3988d",
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "# Visualize the distribution of the two classes: Iris virginica and Not Iris virginica\n",
    "\n",
    "plt.plot(X_new, y_proba[:, 1], \"g-\", linewidth=2, label=\"Iris virginica\")\n",
    "plt.plot(X_new, y_proba[:, 0], \"b--\", linewidth=2, label=\"Not Iris virginica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "deletable": false,
    "editable": false,
    "id": "11",
    "outputId": "fa5c9ac0-0329-419b-e45a-c1ec3c1a927f",
    "state": "read_only"
   },
   "outputs": [],
   "source": [
    "# A more detailed figure\n",
    "\n",
    "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "decision_boundary = X_new[y_proba[:, 1] >= 0.5][0]\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(X[y==0], y[y==0], \"bs\")\n",
    "plt.plot(X[y==1], y[y==1], \"g^\")\n",
    "plt.plot([decision_boundary, decision_boundary], [-1, 2], \"k:\", linewidth=2)\n",
    "plt.plot(X_new, y_proba[:, 1], \"g-\", linewidth=2, label=\"Iris virginica\")\n",
    "plt.plot(X_new, y_proba[:, 0], \"b--\", linewidth=2, label=\"Not Iris virginica\")\n",
    "plt.text(decision_boundary+0.02, 0.15, \"Decision  boundary\", fontsize=14, color=\"k\", ha=\"center\")\n",
    "plt.arrow(decision_boundary, 0.08, -0.3, 0, head_width=0.05, head_length=0.1, fc='b', ec='b')\n",
    "plt.arrow(decision_boundary, 0.92, 0.3, 0, head_width=0.05, head_length=0.1, fc='g', ec='g')\n",
    "plt.xlabel(\"Petal width (cm)\", fontsize=14)\n",
    "plt.ylabel(\"Probability\", fontsize=14)\n",
    "plt.legend(loc=\"center left\", fontsize=14)\n",
    "plt.axis([0, 3, -0.02, 1.02])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "12",
    "outputId": "6c53371d-cd68-41a2-c590-cceaa476e5a1",
    "state": "read_only"
   },
   "outputs": [],
   "source": [
    "# Check the decision boundary value\n",
    "\n",
    "decision_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "13",
    "outputId": "a8bb8b78-e59b-4eef-c096-2289870c728d",
    "starter_code": "# Prediction on two sides of the boundary, one for value 1.7 and the other for value 1.5\n\nlog_reg.",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Prediction on two sides of the boundary, one for value 1.7 and the other for value 1.5\n",
    "\n",
    "log_reg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXB5FyZ6h_XL",
    "state": "normal"
   },
   "source": [
    "# Working with Multiple Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "14",
    "outputId": "ad88e54f-66ff-4bcc-a74f-d428e861834d",
    "starter_code": "# This time, we will work with two features: petal length and petal width\n# which are the 2nd and 3rd features (starting from 0th) in iris[\"data\"]\n# Write code to select those two features in X\n# y remains the same as previous\n\nX = \ny = ",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# This time, we will work with two features: petal length and petal width\n",
    "# which are the 2nd and 3rd features (starting from 0th) in iris[\"data\"]\n",
    "# Write code to select those two features in X\n",
    "# y remains the same as previous\n",
    "\n",
    "X = \n",
    "y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "fit_sif",
    "starter_code": "# Initialize a new LogisticRegression class and fit it with the new data\n\nlog_reg = \nlog_reg.",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Initialize a new LogisticRegression class and fit it with the new data\n",
    "\n",
    "log_reg = \n",
    "log_reg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "15",
    "starter_code": "# Create new two-dimensional data for prediction\n# You should use numpy's meshgrid to create a grid of 2D-points\n# Create 500 points between 2.9 and 7 for x0 and 500 points between 0.8 and 2.7 for x1\n# which are going to be the two features of the new data\n\nx0, x1 = \nX_new = ",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Create new two-dimensional data for prediction\n",
    "# You should use numpy's meshgrid to create a grid of 2D-points\n",
    "# Create 500 points between 2.9 and 7 for x0 and 500 points between 0.8 and 2.7 for x1\n",
    "# which are going to be the two features of the new data\n",
    "\n",
    "x0, x1 = \n",
    "X_new = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "16",
    "starter_code": "# Predict the class-probabilities assigned to the new data created\n\ny_proba = ",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Predict the class-probabilities assigned to the new data created\n",
    "\n",
    "y_proba = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "PWcouMK6jaxU",
    "outputId": "3faadcd7-debe-4fbd-868c-2e8ac661d0de",
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"g^\")\n",
    "\n",
    "zz = y_proba[:, 1].reshape(x0.shape)\n",
    "contour = plt.contour(x0, x1, zz, cmap=plt.cm.brg)\n",
    "\n",
    "\n",
    "left_right = np.array([2.9, 7])\n",
    "boundary = -(log_reg.coef_[0][0] * left_right + log_reg.intercept_[0]) / log_reg.coef_[0][1]\n",
    "\n",
    "plt.clabel(contour, inline=1, fontsize=12)\n",
    "plt.plot(left_right, boundary, \"k--\", linewidth=3)\n",
    "plt.text(3.5, 1.5, \"Not Iris virginica\", fontsize=14, color=\"b\", ha=\"center\")\n",
    "plt.text(6.5, 2.3, \"Iris virginica\", fontsize=14, color=\"g\", ha=\"center\")\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.axis([2.9, 7, 0.8, 2.7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQBrwlobj9GS",
    "state": "normal"
   },
   "source": [
    "# Working with Multiple Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "17",
    "starter_code": "# This time, we will still be working with two-dimensional features (same as previous)\n# but with multiple classes. So we will no longer have just 0 and 1 but 0, 1, ..., c classes\n\nX = \ny = ",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# This time, we will still be working with two-dimensional features (same as previous)\n",
    "# but with multiple classes. So we will no longer have just 0 and 1 but 0, 1, ..., c classes\n",
    "\n",
    "X = \n",
    "y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "18",
    "outputId": "2f7438f0-84bb-4430-ce8e-84e2288eb09c",
    "starter_code": "# Initialize a new multi-class solver\n# You should use the multinomial flag for the attribute multi_class\n# Then, fit the new data\n\nsoftmax_reg = \nsoftmax_reg.",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# Initialize a new multi-class solver\n",
    "# You should use the multinomial flag for the attribute multi_class\n",
    "# Then, fit the new data\n",
    "\n",
    "softmax_reg = \n",
    "softmax_reg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "19",
    "starter_code": "# We will work with the same new data X_new that we created in the previous section\n# Predict the class probabilites and class predictions for X_new\n\ny_proba = \ny_predict = ",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# We will work with the same new data X_new that we created in the previous section\n",
    "# Predict the class probabilites and class predictions for X_new\n",
    "\n",
    "y_proba = \n",
    "y_predict = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "Mb5F9Ejwkf9i",
    "outputId": "1f3a57fd-0dd1-4c29-f524-3017a813b521",
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "# Visualize them\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==2, 0], X[y==2, 1], \"g^\", label=\"Iris virginica\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"bs\", label=\"Iris versicolor\")\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"yo\", label=\"Iris setosa\")\n",
    "\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"center left\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "bkHdOwSFksch",
    "outputId": "cbc9d94b-4a8e-4d82-f4fb-64866c533202",
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "# Visualize along with the decision boundaries\n",
    "\n",
    "zz1 = y_proba[:, 1].reshape(x0.shape)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==2, 0], X[y==2, 1], \"g^\", label=\"Iris virginica\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"bs\", label=\"Iris versicolor\")\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"yo\", label=\"Iris setosa\")\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
    "contour = plt.contour(x0, x1, zz1, cmap=plt.cm.brg)\n",
    "plt.clabel(contour, inline=1, fontsize=12)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"center left\", fontsize=14)\n",
    "plt.axis([0, 7, 0, 3.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "20",
    "outputId": "a75f88b7-a9ec-472f-8a2c-5ea1e747266d",
    "starter_code": "# You can predict class and probabilities for individual data points\n# Predict and print the class and class-probabilities for the point (5, 2)\n\nprint(softmax_reg.)\nprint(softmax_reg.)",
    "state": "graded"
   },
   "outputs": [],
   "source": [
    "# You can predict class and probabilities for individual data points\n",
    "# Predict and print the class and class-probabilities for the point (5, 2)\n",
    "\n",
    "print(softmax_reg.)\n",
    "print(softmax_reg.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "mimir": {
   "data": {},
   "last_submission_id": "",
   "project_id": "d161be9a-3b35-4d3d-9d1d-a799bc34232f"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
